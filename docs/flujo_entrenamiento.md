# ğŸ—ï¸ Flujo de Entrenamiento de Modelos

Este documento describe paso a paso el flujo de entrenamiento implementado en `src/train.py` para modelos lineales (Lasso, Ridge, Elastic Net) y XGBoost.

---

## 1. PreparaciÃ³n de Datos

1. **Lectura de datos:**
   - Se lee el archivo `data/features/features.csv` con la funciÃ³n `leer_archivo_csv()`.
   - Se convierte la columna `time` a formato datetime y se eliminan filas con fechas invÃ¡lidas.
2. **ExclusiÃ³n de datos de predicciÃ³n:**
   - Se excluye el mes de junio para evitar data leakage (solo se usa para predicciÃ³n) en el bloque principal (`main`).
3. **GeneraciÃ³n de columnas de estacionalidad:**
   - Se agregan columnas: `dayofweek`, `month`, `hour`, `sin_comp`, `cos_comp` usando la funciÃ³n `columnas_estacionalidad()`.
4. **DivisiÃ³n train/test:**
   - 80% para entrenamiento, 20% para prueba, respetando el orden temporal, usando la funciÃ³n `dividir_train_test()`.

---

## 2. Entrenamiento de Modelos Lineales

1. **Modelos considerados:** Lasso, Ridge, Elastic Net (todos con escalado estÃ¡ndar).
2. **BÃºsqueda de hiperparÃ¡metros y entrenamiento:**
   - Se usa la funciÃ³n `modelos_lineales()` que implementa `GridSearchCV` con validaciÃ³n cruzada tipo `TimeSeriesSplit` (5 splits).
   - Se exploran valores de `alpha` (y `l1_ratio` para Elastic Net).
   - MÃ©tricas: RMSE y MAE (negativos para maximizar en sklearn).
   - Se selecciona el mejor modelo por RMSE de validaciÃ³n cruzada y se evalÃºa en test.
3. **Curva de aprendizaje:**
   - Se genera una curva de aprendizaje para el mejor modelo lineal con la funciÃ³n `plot_curvas_aprendizaje()`.
4. **Guardado:**
   - Se guarda el modelo entrenado con `guardar_modelo()` y sus metadatos con `guardar_metadatos()`.

---

## 3. Entrenamiento de XGBoost

1. **DefiniciÃ³n del modelo base y bÃºsqueda de hiperparÃ¡metros:**
   - Se usa la funciÃ³n `entrenar_xgboost()` que implementa `RandomizedSearchCV` con `TimeSeriesSplit` (5 splits) y explora hiperparÃ¡metros como `max_depth`, `min_child_weight`, `subsample`, `colsample_bytree`, `gamma`, `reg_alpha`, `reg_lambda`, `learning_rate`.
   - MÃ©tricas: RMSE y MAE.
   - Se selecciona el mejor modelo por RMSE de validaciÃ³n cruzada y se evalÃºa en test.
2. **Curva de aprendizaje purista:**
   - Se entrena el modelo final con los mejores hiperparÃ¡metros y muchos Ã¡rboles usando la funciÃ³n `xgb_learning_curve_purista()`.
   - Se extrae la curva de RMSE por boosting round y se determina el nÃºmero Ã³ptimo de Ã¡rboles (`n_estimators`).
   - Se reentrena el modelo final con ese nÃºmero Ã³ptimo.
3. **Guardado:**
   - Se guarda el modelo entrenado con `guardar_modelo()` y sus metadatos con `guardar_metadatos()`.

---

## 4. Interpretabilidad (SHAP)

1. **CÃ¡lculo de valores SHAP:**
   - Se usa la funciÃ³n `analisis_shap()` que implementa `shap.TreeExplainer` para explicar el modelo XGBoost.
   - Se generan grÃ¡ficos de importancia global, dependencia, waterfall y force plots.
2. **ExportaciÃ³n:**
   - Se guardan los valores SHAP y las grÃ¡ficas en `reports/figures/shap/`.

---

## 5. Resumen Visual (Mermaid)

```mermaid
graph TD
    A[Lectura y limpieza de datos] --> B[GeneraciÃ³n de features estacionales]
    B --> C[DivisiÃ³n train/test]
    C --> D1[Modelos Lineales]
    C --> D2[XGBoost]
    D1 --> E1[GridSearchCV + TSCV]
    D2 --> E2[RandomizedSearchCV + TSCV]
    E1 --> F1[Curva de aprendizaje]
    E2 --> F2[Curva n_estimators]
    F1 --> G1[Guardar modelo y metadatos]
    F2 --> G2[Guardar modelo y metadatos]
    G2 --> H[Interpretabilidad SHAP]
```

---

[â† Volver al README principal](../README.md)
