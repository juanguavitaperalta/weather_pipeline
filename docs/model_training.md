# ğŸ¤– Entrenamiento de Modelos

Este documento detalla el proceso de entrenamiento y comparaciÃ³n de los modelos evaluados.

---

## Estructura del entrenamiento y selecciÃ³n de modelos

### 1. Condiciones generales
1. Se excluira el mes de junio para esta etapa pues se utilizarÃ¡ para la etapa de predicciones.
2.  - Se agregan columnas: `dayofweek`, `month`, `hour`, `sin_comp`, `cos_comp` usando la funciÃ³n `columnas_estacionalidad()`. Con estas variables, se busca capturar el comportamiento estacionario propio de los datos contenidos en el data set.
3. - 80% para entrenamiento, 20% para prueba, respetando el orden temporal, usando la funciÃ³n `dividir_train_test()`.

## 2. Entrenamiento de modelos lineales:
## ğŸ§© Diagramas de Arquitectura de Modelos

### Modelos Lineales (Lasso, Ridge, Elastic Net) diagrama
```mermaid
flowchart LR
  X[Variables de entrada] --> F[TransformaciÃ³n y Escalado]
  F --> L[Modelo Lineal]
  L --> Y[Evaluacion de metricas]
```

1. La funcion `modelos_lineales()` realiza una busqueda de hiperparametros con validaciÃ³n cruzada con un kfold=5. Se usa la funciÃ³n `TimeSeriesSplit`para realizar las particiones, respetando el  orden de los datos y `GridSearchCV` para la busqueda de hiperparametros.

2. Como la busqueda de hiperparametros se realiza dado un problema de optimizaciÃ³n, se seleccionaran los hiperparametros, evaluando las metricas RMSE y MAE. El mejor modelo se seleccionara de aquel con el menor RMSE.

3. Al final se generara una curva de aprendizaje (validacion vs test) para evluaar si hay overfitting, (falta de generalizaciÃ³n del modelo ante presencia de modelos nuevos) o falta de aprendizaje en la etapa de entrenamiento.

## 3. Entrenamiento modelo ML XGBoost



### XGBoost diagrama
```mermaid
flowchart TD
  X[Variables de entrada] --> F[TransformaciÃ³n y Escalado]
  F --> T1[Ãrbol 1]
  F --> T2[Ãrbol 2]
  F --> Tn[Ãrbol n]
  T1 & T2 & Tn --> S[Suma de Ã¡rboles]
  S --> C[Curva de aprendizaje\nSelecciÃ³n Ã³ptima de n_estimators]
  C --> Y[EvaluaciÃ³n de metricas]
```

1. Se usa la funciÃ³n `entrenar_xgboost()` para realizar la selecciÃ³n de los  hiperparÃ¡metros `max_depth`, `min_child_weight`, `subsample`, `colsample_bytree`, `gamma`, `reg_alpha`, `reg_lambda`, `learning_rate`.  Se selecciona el mejor modelo por RMSE de validaciÃ³n cruzada y se evalÃºa en test.

2. Se extrae la curva de aprendizaje por boosting round y se determina el nÃºmero Ã³ptimo de arboles.

3. Se reentrena el modelo y se guarda.

## ğŸ“Š Modelos Evaluados

### Modelos Lineales
- **Lasso:** RegularizaciÃ³n L1 para selecciÃ³n de variables
- **Ridge:** RegularizaciÃ³n L2 para reducir sobreajuste
- **Elastic Net:** CombinaciÃ³n de L1 y L2

### Modelos de Ensemble
- **XGBoost:** Gradient Boosting con regularizaciÃ³n

---

## ğŸ“ˆ Curvas de Aprendizaje

Las curvas de aprendizaje permiten evaluar si el modelo sufre de sesgo o varianza.

### Ridge - Curva de Aprendizaje
<p align="center">
  <img src="../reports/figures/curvas%20aprendizaje/curva_aprendizaje_ridge.png" width="700">
</p>

### XGBoost - OptimizaciÃ³n de n_estimators
<p align="center">
  <img src="../reports/figures/xgb_n_estimators_curve.png" width="700">
</p>

---

## ğŸ† ComparaciÃ³n de Modelos

| Modelo      | RMSE   | MAE   | RÂ²   |
|-------------|--------|-------|------|
| Lasso       | 1.45Â°C | 1.13Â°C | 0.82 |
| **Ridge**   | 1.38Â°C | 1.08Â°C | 0.84 |
| Elastic Net | 1.41Â°C | 1.10Â°C | 0.83 |
| **XGBoost** | 1.32Â°C | 1.01Â°C | 0.86 |

**Modelo seleccionado:** XGBoost por su mejor rendimiento en RMSE y MAE.

---

## âš™ï¸ HiperparÃ¡metros del Modelo Final

Los hiperparÃ¡metros del modelo XGBoost entrenado se encuentran en:
`models/metadata/xgboost_metadatos.json`

---

## ğŸ“ Conclusiones

1. **XGBoost supera a los modelos lineales** en todas las mÃ©tricas.
2. **Sin sobreajuste:** Las curvas de aprendizaje muestran convergencia adecuada.
3. **RegularizaciÃ³n efectiva:** El modelo generaliza bien a datos no vistos.

---

[â† Volver al README principal](../README.md)
